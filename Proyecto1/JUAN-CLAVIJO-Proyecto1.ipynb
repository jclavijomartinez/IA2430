{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTELIGENCIA ARTIFICIAL\n",
    "\n",
    "## Proyecto 1: Clasificación y Regresión Lineal\n",
    "\n",
    "Hecho por: Juan Sebastián Clavijo Martínez<br />\n",
    "TEMA: Usar el dataset sobre dígitos manuscritos (MNIST) para implementar clasificacion lineal y los datos artificiales suministrados por el profesor para modelar la relación entre variables mediante regresión lineal<br />\n",
    "Fecha: 16-09-2024<br />\n",
    "Notas: Nada por ahora<br />\n",
    "**Pontificia Universidad Javeriana**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importado de bibliotecas pertinentes\n",
    "\n",
    "import pandas as pd  # tratamiento de datos en un dataframe\n",
    "import numpy as np  # numerical python\n",
    "import seaborn as sns  # biblioteca versatil para estadistica y visualizacion\n",
    "import matplotlib.pyplot as plt  # biblioteca para vizualizacion de datos\n",
    "from sklearn.datasets import load_digits # repo donde estan las imagenes pertinentes para la primera parte del proyecto\n",
    "# imports necesarios para el punto 1.2.1\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# imports necesarios para el punto 1.3.1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "# imports necesarios para el punto 1.4.1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# imports necesarios para el punto 2.3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.feature_selection import SelectKBest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBLEMA 1: CLASIFICACIÓN  LINEAL\n",
    "\n",
    "### Parte 1.1 Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1.1.1: carga de datos\n",
    "# se trae el dataset\n",
    "digits = load_digits() #se cargan los datos con la funcion load_digits\n",
    "print(digits.data.shape)\n",
    "# Se imprime la forma de los datos para verificar el número de instancias y atributos.\n",
    "# Según la documentación de scikit-learn (https://scikit-learn.org/stable/datasets/toy_dataset.html#digits-dataset),\n",
    "# este dataset contiene 1797 instancias, cada una con 64 atributos, que corresponden a una imagen de 8x8 píxeles.\n",
    "# según la documentacion, este dataset no tiene datos NaN o NULL, por eso no se realiza el paso 1.1.2 limpieza y preparacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1.1.2 visualización de todos los dígitos organizados\n",
    "# Configurar la cuadrícula 2x5\n",
    "fig, axes = plt.subplots(2, 5, figsize=(7, 5))\n",
    "plt.gray()\n",
    "\n",
    "# Mostrar cada dígito en la cuadrícula\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.matshow(digits.images[i])\n",
    "    ax.set_title(f\"Dígito: {digits.target[i]}\")\n",
    "    ax.axis(\"off\")  #se ocultan los ejes para una visualización más limpia\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis descriptivo de las imagenes\n",
    "\n",
    "- Estas imagenes de los números son fáciles de entender para nosotros los humanos, pero para un computador serían un reto\n",
    "- A continuación, unas notas sobre las características de algunos dígito:\n",
    "  - Dígito 0: Se observa como un círculo casi cerrado con una densidad de píxeles más oscura en el centro y un contorno definido, que lo distingue claramente como un *0*.\n",
    "  - Dígito 4: Debido a la manera de presentación, podría ser confundido con un 0 mal escrito\n",
    "  - Dígito 5: Se puede distinguir un 5, pero la primera parte del trazo, que se parece a una *C*, debería empezar mucho mas cerca a la esquina superior derecha, es poco claro.\n",
    "  - Dígito 6: Se puede distinguir un 6, pero el centro debería estar más oscuro y debería empezar más cerca a la esquina superior derecha, ya que podría ser confundido con un 1 mal escrito\n",
    "- Cada dígito en el conjunto de datos MNIST está representado por una imagen pequeña y de baja resolución, lo que permite identificar patrones distintivos que los clasificadores pueden utilizar para diferenciarlos. La variación en la intensidad de los píxeles dentro de cada dígito proporciona información clave sobre la forma y el trazo del número, lo que es esencial para las tareas de clasificación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1.2 Implementación de clasificación con KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1.2.1: División de los datos en entrenamiento y prueba para ambos métodos y que no haya sesgo (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1.2.2: implementacion del código\n",
    "\n",
    "# Definimos los valores de k que queremos probar\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "accuracies = []\n",
    "\n",
    "# Implementación y evaluación del modelo KNN para diferentes valores de k\n",
    "for k in k_values:\n",
    "    # Crear el clasificador KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Entrenar el clasificador\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir los valores en el conjunto de prueba\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Evaluar el rendimiento del modelo usando precisión\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Imprimir el reporte de clasificación\n",
    "    print(f\"Resultados para k={k}:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Gráfico de la precisión para diferentes valores de k\n",
    "plt.figure(figsize=(20, 3))\n",
    "plt.plot(k_values, accuracies, marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "plt.title(\"Precisión del modelo KNN para diferentes valores de k\")\n",
    "plt.xlabel(\"Valor de k\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1.3 Implementación de clasificación con regresión logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1.3.1  Clasificadores Binarios para cada dígito\n",
    "\n",
    "# Crear un diccionario para almacenar los modelos\n",
    "models = {}\n",
    "\n",
    "# Entrenar un clasificador binario para cada dígito (0 a 9)\n",
    "for digit in range(10):\n",
    "    # Crear una etiqueta binaria para el dígito actual\n",
    "    y_train_binary = (y_train == digit).astype(int)\n",
    "    y_test_binary = (y_test == digit).astype(int)\n",
    "\n",
    "    # Crear y entrenar el modelo de regresión logística\n",
    "    model = LogisticRegression(max_iter=1000, solver=\"lbfgs\")\n",
    "    model.fit(X_train, y_train_binary)\n",
    "\n",
    "    # Guardar el modelo entrenado\n",
    "    models[digit] = model\n",
    "\n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    y_pred_binary = model.predict(X_test)\n",
    "    print(f\"Clasificador para el dígito {digit}:\")\n",
    "    print(classification_report(y_test_binary, y_pred_binary))\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1.3.2 Evaluación de cada clasificador binario para una nueva muestra y selección de la clase con la mayor probabilidad.\n",
    "\n",
    "# Predicción sobre el conjunto de prueba usando la función de decisión\n",
    "def predict_digit(models, X):\n",
    "    # Obtener las probabilidades para cada clase\n",
    "    probabilities = np.array(\n",
    "        [model.predict_proba(X)[:, 1] for model in models.values()]\n",
    "    )\n",
    "\n",
    "    # Elegir la clase con la probabilidad más alta\n",
    "    predictions = np.argmax(probabilities, axis=0)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Predecir los dígitos para el conjunto de prueba\n",
    "y_pred = predict_digit(models, X_test)\n",
    "\n",
    "# Evaluar el rendimiento general\n",
    "print(\"Evaluación general del modelo multinomial basado en clasificadores binarios:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1.3.3: Visualizar los pesos (θ) como un mapa de calor en una cuadrícula 2x5\n",
    "\n",
    "# Configurar la cuadrícula 2x5\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 7))\n",
    "\n",
    "# Iterar sobre cada modelo y su dígito correspondiente\n",
    "for i, (digit, model) in enumerate(models.items()):\n",
    "    # Reshape de los pesos en una matriz de 8x8\n",
    "    weights = model.coef_.reshape(8, 8)\n",
    "\n",
    "    # Seleccionar la posición de la cuadrícula\n",
    "    ax = axes.flat[i]\n",
    "\n",
    "    # Crear el mapa de calor en la posición correspondiente\n",
    "    sns.heatmap(weights, annot=False, cmap=\"coolwarm\", center=0, ax=ax)\n",
    "    ax.set_title(f\"Mapa de calor: Dígito {digit}\")\n",
    "    ax.axis(\"off\")  # Ocultar los ejes para una visualización más limpia\n",
    "\n",
    "# Ajustar el espaciado entre los subplots para mejor visualización\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1.4 Implementación de clasificación multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1.4 Impementacion de código\n",
    "\n",
    "# Crear y entrenar el modelo de regresión logística con opción multinomial\n",
    "model_multinomial = LogisticRegression(\n",
    "    max_iter=10000, solver=\"lbfgs\", multi_class=\"multinomial\"\n",
    ")\n",
    "model_multinomial.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_multinomial = model_multinomial.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del clasificador multinomial\n",
    "print(\"Evaluación del modelo multinomial:\")\n",
    "print(classification_report(y_test, y_pred_multinomial))\n",
    "\n",
    "# Crear la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_multinomial)\n",
    "\n",
    "# Visualizar la matriz de confusión como un mapa de calor\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(\n",
    "    conf_matrix,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"YlGnBu\",\n",
    "    xticklabels=digits.target_names,\n",
    "    yticklabels=digits.target_names,\n",
    ")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for Multinomial Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1.4.1 visualización de malas clasificaciones\n",
    "\n",
    "# Configurar la cuadrícula de 1 fila y 3 columnas\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "plt.gray()\n",
    "\n",
    "# identificacion de la mala clasificación\n",
    "misclassified_indices = np.where((y_test == 4) & (y_pred_multinomial == 1))[0]\n",
    "\n",
    "# Mostrar un ejemplo de dígito 1 (correctamente clasificado)\n",
    "axes[0].imshow(digits.images[np.where(digits.target == 1)[0][0]], cmap='gray')\n",
    "axes[0].set_title(\"Ejemplo de 1\")\n",
    "axes[0].axis(\"off\")  # Ocultar ejes para claridad\n",
    "\n",
    "# Mostrar el dígito mal clasificado (Real: 4, Clasificado: 1)\n",
    "for idx in misclassified_indices:\n",
    "    axes[1].imshow(X_test[idx].reshape(8, 8), cmap=\"gray\")\n",
    "    axes[1].set_title(f\"Clasificado como 1, Real: 4 (Índice: {idx})\")\n",
    "    axes[1].axis(\"off\")  # Ocultar ejes\n",
    "\n",
    "# Mostrar un ejemplo de dígito 4 (correctamente clasificado)\n",
    "axes[2].imshow(digits.images[np.where(digits.target == 4)[0][0]], cmap='gray')\n",
    "axes[2].set_title(\"Ejemplo de 4\")\n",
    "axes[2].axis(\"off\") \n",
    "\n",
    "# Mostrar la figura completa\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### informe de clasificación\n",
    "\n",
    "Antes de hacer una comparación entre los diferentes resultados de clasificación, es muy importante hablar sobre la información que muestra el reporte de clasificación, presentado en esta primera parte para KNN, regresión logística y el modelo multinomial. A continuación, se presenta un resumen de los indicadores de este reporte:\n",
    "\n",
    "1. **Precisión (Precision)**\n",
    "   - **¿Qué me dice?**: La precisión indica el porcentaje de verdaderos positivos sobre todos los ejemplos que fueron clasificados como positivos. En otras palabras, de todas las predicciones que hizo el modelo para una clase, cuántas de ellas fueron correctas.\n",
    "   - **¿Cómo se aplica?**: Se aplica a cada clase de la clasificación. Una precisión alta significa que el modelo comete pocos errores al clasificar una clase en particular. Es útil en situaciones donde los falsos positivos deben minimizarse.\n",
    "\n",
    "2. **Exhaustividad (Recall)**\n",
    "   - **¿Qué me dice?**: La exhaustividad, también conocida como sensibilidad, indica el porcentaje de verdaderos positivos sobre todos los ejemplos que realmente pertenecen a la clase positiva. Mide la capacidad del modelo para encontrar todos los positivos.\n",
    "   - **¿Cómo se aplica?**: Este indicador es particularmente importante en contextos donde es crucial identificar todos los ejemplos positivos, aunque se permitan algunos falsos positivos. Un alto valor de exhaustividad asegura que no se pierden muchos positivos.\n",
    "\n",
    "3. **F1-Score**\n",
    "   - **¿Qué me dice?**: El F1-Score es la media armónica entre la precisión y la exhaustividad. Proporciona una métrica equilibrada que combina ambos aspectos, especialmente cuando hay una distribución desigual de clases o un interés en tener en cuenta tanto la precisión como la exhaustividad.\n",
    "   - **¿Cómo se aplica?**: Se utiliza cuando se necesita un equilibrio entre precisión y exhaustividad, en situaciones donde no se puede priorizar uno sobre el otro. Es útil en modelos con datos desequilibrados.\n",
    "\n",
    "4. **Soporte (Support)**\n",
    "   - **¿Qué me dice?**: El soporte indica el número total de ocurrencias de cada clase en los datos de prueba. Es simplemente la cantidad de ejemplos reales que pertenecen a cada clase.\n",
    "   - **¿Cómo se aplica?**: Muestra cuántos ejemplos de una clase específica están presentes, proporcionando contexto sobre la frecuencia de cada clase en el conjunto de datos. Ayuda a interpretar los otros indicadores según el tamaño de cada clase.\n",
    "\n",
    "5. **Exactitud (Accuracy)**\n",
    "   - **¿Qué me dice?**: La exactitud mide el porcentaje de predicciones correctas sobre el total de predicciones hechas por el modelo. Es una métrica global del desempeño.\n",
    "   - **¿Cómo se aplica?**: Se aplica al modelo completo y es útil cuando las clases están equilibradas. Sin embargo, en problemas con clases desbalanceadas, puede no ser suficiente por sí sola para evaluar el rendimiento real del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de resultados\n",
    "\n",
    "Conociendo los principales indicadores del reporte de clasificación, ahora se procede a hablar sobre los resultados de cada método de clasificación: el primero, KNN, según la gráfica muestra una precisión bastante alta, en todos los k, mayor al 0.970. para la regresión logistica, para cada dígito la presición no baja de 0.83. Para el modelo de clasificadores binarios la presición mas baja es, parecida a los modelos anteriores y no baja del 0.94 y para el modelo multinomial, la presicion mas baja es de 0.97. Esto indica que los modelos de clasificación usados pueden separar correctamente los dígitos del dataset dado. En un momentó el autor de este código consideró que debido a estos valores altos en general, los clasificadores estaban sobre ajustando, luego de una consulta al profesor, estos valores presentados son correspondientes a lo que se conoce sobre el dataset.\n",
    "\n",
    "Es importante también mencionar la visualización de la clasificación inadecuada mostrada en el numeral 1.4.1, las posibles razones detrás de este desliz por parte del clasificador multinomial pueden ser la forma del 4 de la mitad y como el espacio de la izquierda se asemeja bastante al del 1, también que el trazo final de la derecha con el que se dibujaría el 4 de la mitad no es tan pronunciado como en el ejemplo y tiene solo 3 pixeles dedicados a terminar el trazo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preguntas de aprendizaje\n",
    "\n",
    "1. ¿Qué influencia tiene el uso de diferentes valores de K en el clasificador KNN?<br />\n",
    "R = El uso de diferentes valores para *k* en la implementación de KNN implica mejor precisión, en otras palabras, hace que los verdaderos positivos sean efectivamente clasificados como positivos hasta un punto. Al parecer, para este dataset el valor óptimo para lograr el mejor equilibrio entre precisión y robustez en los datos usados es *k* = 7.\n",
    "\n",
    "2. ¿Qué diferencias hay entre el clasificador utilizando KNN y regresión logística? ¿Funciona uno mejor que otro?, ¿Por qué?<br />\n",
    "R = La principal diferencia entre KNN y regresión logística es que regresión logística, para ser entrenada como s eha discutido en clase, usa gradiente descendiente; por otro lado, KNN no tiene un entrenamiento como tal, el rendimiento y métrica principal están basados en la distancia (la distancia por defecto es euclidiana, pero hay más). El parámetro clave de KNN es *K*, el número de elementos cercanos, que podrían llamarse vecinos, que se tendrán en cuenta al clasificar un nuevo punto. Para poder afirmar que uno funciona mejor que otro, es necesario mirar el contexto de los datos, ya que diferentes clasificadores manejan mejor ciertos volúmenes de datos. KNN es mejor cuando hay distribuciones complejas o no lineales; regresión logística es más adecuada con problemas lineales o con conjuntos de datos muy grandes, ya que KNN, según lo visto en clase, es computacionalmente costoso a medida que los datos crecen. Para este dataset específicamente, según los reportes de clasificación, es posible afirmar que KNN tiene un mejor rendimiento general y es más consistente en todas las clases, especialmente con *K*=5 o *K*=7. Regresión logística es efectiva, pero presenta dificultades en algunas clases, como los dígitos 1 y 8.\n",
    "\n",
    "3. ¿El clasificador de regresión logística presenta un buen rendimiento? ¿Cómo evalúan su rendimiento? ¿Si el rendimiento no es bueno qué cree se debe hacer para mejorarlo?<br />\n",
    "R = El clasificador de regresión logística presenta un buen rendimiento, ya que tiene una precisión cercana al 100% en la mayoría de las clases. Su rendimiento se evalúa mediante métricas como la precisión, recall y el f1-score, los cuales reflejan su capacidad para clasificar correctamente los datos. Sin embargo, en algunas clases, como los dígitos 1 y 8, el rendimiento es menor, posiblemente debido a un desbalance en los datos o la falta de complejidad en el modelo. Para mejorar, se podría ajustar el modelo utilizando técnicas como la regularización, recolectar más datos o aplicar métodos de balanceo de clases.\n",
    "\n",
    "4. Al realizar el mapa de calor con los pesos de la regresión logística, para los diferentes clasificadores, ¿Qué puede notar? ¿Hay algún tipo de patrón?, ¿Sí, no, por qué?<br />\n",
    "R = En el mapa de calor, observándolo algo de lejos, todos los dígitos en conjunto, como se presentan en la gráfica, se pueden distinguir los dígitos originales. El patrón que se aprecia es que los dígitos se destacan más en tonos rojizos, lo que sugiere que estas áreas corresponden a coeficientes positivos, mientras que las áreas en tonos azulados representan coeficientes negativos. Esto refleja las zonas más relevantes para la clasificación de cada dígito en la regresión logística.\n",
    "\n",
    "5. ¿Qué puede concluir al final de este proyecto?, escriba su opinión frente a los métodos de clasificación y cómo se aplicó en este proyecto.<br />\n",
    "R = Se puede concluir que los métodos de clasificación se adaptan muy bien a problemas complejos y pueden ser precisos, exhaustivos y exactos a la hora de enfrentarse a una tarea compleja para un computador, como discriminar dígitos manuscritos. Opino que los métodos de clasificación me sorprendieron gratamente, ya que no creía que iban a ser tan precisos porque, inclusive para humanos, distinguir algunos dígitos a mano puede resultar una tarea ciertamente compleja.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBLEMA 2: Regresión Lineal\n",
    "\n",
    "### Parte 2.1 procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2.1.1: carga de datos\n",
    "# se trae el dataset\n",
    "# Aunque nos proporcionaron el archivo.csv y viene en la carpeta de este proyecto, decidí colgarlo en github para más\n",
    "# comodidad y por si algo le pasa, que pueda ser facilmente traído a través de internet\n",
    "url = \"https://raw.githubusercontent.com/jclavijomartinez/IA2430/master/Proyecto1/RegressionData.csv\" \n",
    "df_artif = pd.read_csv(url) # Se hace el obj dataframe, se llama asi porque la base de datos es artificial\n",
    "# si el lector requiere importar los datos desde el archivo .csv, siga los pasos a continuación:\n",
    "# 1. COMENTE las 2 linea arriba que comienza con url = y df_....\n",
    "# 2. DESCOMENTE las siguientes 2 lineas a continuación\n",
    "# local = pd.read_csv(\"RegressionData.csv\") # Leer el archivo CSV\n",
    "# df_artif = pd.read_csv(local) # Se llama asi porque la base de datos es artificial\n",
    "df_artif.head(5) # se presentan los primeros 5 renglones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2.1.2: limpieza y preparación de los datos (cuenta de datos null, NaN, etc. y limpieza)\n",
    "desaparecidos = len(df_artif) - len(df_artif.dropna())\n",
    "Cantidad = len(df_artif)\n",
    "print(\"Cantidad de datos observados con datos NaN\", desaparecidos)\n",
    "print(\"Cantidad de datos duplicados\", df_artif.duplicated().sum())\n",
    "##se eliminan los datos Null y Duplicados\n",
    "df_artif.dropna(inplace=True)\n",
    "df_artif.drop_duplicates(inplace=True)\n",
    "# Se reinicia el indice por los elementos eliminados\n",
    "df_artif.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2.2 Analisis de los datos\n",
    "\n",
    "A continuación se usan los comandos [df].info() y [df].describe() para presentar informacion clave sobre el dataframe, posteriormente se grafican las distribuciones de las variables y se procede a hacer un analisis descriptivo de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2.2.1 presentacion del df_artif\n",
    "\n",
    "df_artif.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artif.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se graffican las variables en un histograma para visualizar mejor su distribución\n",
    "\n",
    "# Crear la figura y los subplots, con 1 fila y 3 columnas\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Histograma para X1\n",
    "axes[0].hist(df_artif[\"X1\"], bins=30, color=\"blue\", alpha=0.7)\n",
    "axes[0].set_title(\"Distribución de X1\")\n",
    "axes[0].set_xlabel(\"X1\")\n",
    "axes[0].set_ylabel(\"Frecuencia\")\n",
    "\n",
    "# Histograma para X2\n",
    "axes[1].hist(df_artif[\"X2\"], bins=30, color=\"green\", alpha=0.7)\n",
    "axes[1].set_title(\"Distribución de X2\")\n",
    "axes[1].set_xlabel(\"X2\")\n",
    "axes[1].set_ylabel(\"Frecuencia\")\n",
    "\n",
    "# Histograma para y\n",
    "axes[2].hist(df_artif[\"y\"], bins=30, color=\"red\", alpha=0.7)\n",
    "axes[2].set_title(\"Distribución de y\")\n",
    "axes[2].set_xlabel(\"y\")\n",
    "axes[2].set_ylabel(\"Frecuencia\")\n",
    "\n",
    "# Ajustar el espaciado entre subplots\n",
    "plt.tight_layout(pad=5)\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis descriptivo:\n",
    "\n",
    "Según la información mostrada arriba, se puede hablar más a profundidad sobre los datos. Es posible afirmar que:\n",
    "\n",
    "- **X1**: Tiene una media de -3.26 y una desviación estándar muy alta de 99.9, lo cual indica una gran dispersión de los datos alrededor de la media. Esto es consistente con la forma de su distribución en el histograma, que muestra una asimetría leve hacia la izquierda. El rango es amplio, con un valor mínimo de -323 y un máximo de 357, lo que indica la presencia de valores extremos que pueden influir en el modelo.\n",
    "\n",
    "- **X2**: Presenta una media cercana a 0 (0.073) y una desviación estándar de 1.99, lo que sugiere que los datos están más concentrados alrededor de la media en comparación con X1. La distribución de X2 es casi simétrica y parece aproximarse a una distribución normal, como lo evidencia su histograma. El rango de los datos es más moderado, con un mínimo de -6.14 y un máximo de 7.13.\n",
    "\n",
    "- **y**: La variable dependiente tiene una media cercana a 1 (0.996) y una desviación estándar de 0.79, lo que indica una menor dispersión en comparación con X1. Su distribución en el histograma muestra una ligera asimetría positiva, con una cola más larga hacia los valores positivos. Esto sugiere que hay más valores por encima de la media, aunque sin valores atípicos extremos.\n",
    "\n",
    "En general, los datos muestran diferentes grados de variabilidad. X1 es la variable con mayor dispersión y podría tener un impacto significativo en el modelo de regresión. X2, por su parte, tiene una distribución más estable y cercana a la normal, mientras que y, la variable objetivo, tiene una ligera asimetría positiva, lo que podría afectar la predicción si no se ajusta adecuadamente en el modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2.3 implementación de regresión lineal\n",
    "\n",
    "Antes de implementar código, es importante visualizar los datos para darse una idea sobre que posibles transformaciones no lineales pueden realizarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2.3.1 visualización de los datos\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Graficar X1 vs y\n",
    "ax[0].scatter(df_artif[\"X1\"], df_artif[\"y\"], alpha=0.7)\n",
    "ax[0].set_xlabel(\"X1\")\n",
    "ax[0].set_ylabel(\"y\")\n",
    "ax[0].set_title(\"Relación entre X1 e y\")\n",
    "\n",
    "# Graficar X2 vs y\n",
    "ax[1].scatter(df_artif[\"X2\"], df_artif[\"y\"], alpha=0.7)\n",
    "ax[1].set_xlabel(\"X2\")\n",
    "ax[1].set_ylabel(\"y\")\n",
    "ax[1].set_title(\"Relación entre X2 e y\")\n",
    "\n",
    "# Graficar X1 vs X2\n",
    "ax[2].scatter(df_artif[\"X1\"], df_artif[\"X2\"], alpha=0.7)\n",
    "ax[2].set_xlabel(\"X1\")\n",
    "ax[2].set_ylabel(\"X2\")\n",
    "ax[2].set_title(\"Relación entre X1 y X2\")\n",
    "\n",
    "# Mostrar las gráficas\n",
    "plt.tight_layout(pad=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2.3.2: Transformaciones y regresión de X1\n",
    "\n",
    "# Se transforma X1 para evitar problemas con valores negativos y mejorar la relación lineal.\n",
    "# Aquí usamos el logaritmo de X1^2 (elevamos al cuadrado para eliminar los negativos y añadimos un pequeño valor para evitar log(0))\n",
    "df_artif['X1_log'] = np.log(df_artif['X1']**2 + 0.1)\n",
    "\n",
    "# En y, tomamos el valor absoluto para eliminar problemas con valores negativos y lo elevamos al cuadrado\n",
    "# para manejar de manera más consistente los valores de y en la transformación.\n",
    "df_artif['y_transformed'] = 0.5 * (np.abs(df_artif['y']))**2\n",
    "\n",
    "# Ahora preparamos las variables X (independiente) y y (dependiente).\n",
    "# Para X usamos la columna transformada de X1, ya que hemos aplicado la transformación logarítmica.\n",
    "X = df_artif[['X1_log']]  # Se toma la versión logarítmica de X1\n",
    "y = df_artif['y_transformed']  # Usamos la versión transformada de y\n",
    "\n",
    "# Dividimos los datos en conjunto de entrenamiento (70%) y conjunto de prueba (30%).\n",
    "# Esto es importante para validar la precisión del modelo y evitar sobreajuste.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Se crea un modelo de regresión lineal que ajustará los datos transformados.\n",
    "modelo_lineal = LinearRegression()\n",
    "\n",
    "# Ajustamos el modelo con los datos de entrenamiento (X_train, y_train).\n",
    "modelo_lineal.fit(X_train, y_train)\n",
    "\n",
    "# Usamos el modelo ajustado para predecir los valores de y en el conjunto de prueba.\n",
    "y_pred = modelo_lineal.predict(X_test)\n",
    "\n",
    "# Graficar los datos originales transformados y la recta de regresión ajustada\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Visualizamos los datos transformados (log(X1) y el valor absoluto transformado de y).\n",
    "plt.scatter(df_artif[\"X1_log\"], df_artif[\"y_transformed\"], alpha=0.5, color='orange', label='Datos Transformados')\n",
    "\n",
    "# Dibujamos la recta de regresión que ajusta los datos (usando los valores de prueba y las predicciones).\n",
    "plt.plot(X_test, y_pred, color='red', label='Recta de Regresión')\n",
    "\n",
    "# Etiquetas y leyenda\n",
    "plt.xlabel(\"Log(X1)\")\n",
    "plt.ylabel(\"y Transformado (|y|^2)\")\n",
    "plt.title(\"Relación entre Log(X1) y y Transformado con Regresión Lineal\")\n",
    "\n",
    "# Ajustamos el diseño del gráfico para que no se superpongan los elementos.\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluar el rendimiento del modelo utilizando el error cuadrático medio (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Error cuadrático medio (MSE): {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2.3.3 Transformaciones y regresión de X2\n",
    "\n",
    "# Sumar una pequeña constante a y para evitar problemas con valores menores o iguales a cero\n",
    "df_artif[\"log_y\"] = np.log(df_artif[\"y\"] + 1e-6)\n",
    "\n",
    "# Eliminar filas con valores NaN en log_y\n",
    "df_artif_clean = df_artif.dropna(subset=[\"log_y\"])\n",
    "\n",
    "# Separar la variable independiente X2 y la variable dependiente log(y) sin NaN\n",
    "X = df_artif_clean[\"X2\"].values.reshape(-1, 1)  # Necesitamos darle una forma de columna para sklearn\n",
    "y_log = df_artif_clean[\"log_y\"].values  # log(y) ya calculado\n",
    "\n",
    "# Crear el modelo de regresión lineal\n",
    "modelo = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo.fit(X, y_log)\n",
    "\n",
    "# Hacer predicciones sobre los datos originales\n",
    "y_log_pred = modelo.predict(X)\n",
    "\n",
    "# Visualización de los resultados\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "# Graficar los puntos originales X2 vs log(y)\n",
    "ax.scatter(df_artif_clean[\"X2\"], df_artif_clean[\"log_y\"], alpha=0.7, label=\"Datos originales\")\n",
    "\n",
    "# Graficar la línea de regresión X2 vs predicción de log(y)\n",
    "ax.plot(df_artif_clean[\"X2\"], y_log_pred, color=\"red\", label=\"Línea de regresión\")\n",
    "\n",
    "# Etiquetas y título\n",
    "ax.set_xlabel(\"X2\")\n",
    "ax.set_ylabel(\"log(y)\")\n",
    "ax.set_title(\"Regresión lineal entre X2 y log(y)\")\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluar el rendimiento del modelo utilizando el error cuadrático medio (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Error cuadrático medio (MSE): {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2.3.4 Transformaciones y regresion de x1 vs x2\n",
    "\n",
    "# Crear nuevas columnas con los valores al cuadrado de X1 y X2\n",
    "df_artif[\"X1_squared\"] = df_artif[\"X1\"] ** 2\n",
    "df_artif[\"X2_squared\"] = df_artif[\"X2\"] ** 2\n",
    "\n",
    "# Filtrar las filas que no tengan valores nulos en X1 o X2\n",
    "df_artif_filtered = df_artif.dropna(subset=[\"X1_squared\", \"X2_squared\"])\n",
    "\n",
    "# Definir X y y como los valores filtrados\n",
    "X = df_artif_filtered[\"X1_squared\"].values.reshape(-1, 1)  # X debe tener 2 dimensiones\n",
    "y = df_artif_filtered[\"X2_squared\"].values\n",
    "\n",
    "# Crear el modelo de regresión lineal\n",
    "modelo = LinearRegression()\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "modelo.fit(X, y)\n",
    "\n",
    "# Predecir los valores de y utilizando el modelo ajustado\n",
    "y_pred = modelo.predict(X)\n",
    "\n",
    "# Visualización de los resultados de la regresión\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Graficar los valores reales de y vs los valores predichos (scatter plot)\n",
    "plt.scatter(X, y, alpha=0.5, color='blue', label=\"Valores reales\")\n",
    "\n",
    "# Graficar la línea de regresión\n",
    "plt.plot(X, y_pred, color='red', linewidth=2, label=\"Línea de regresión\")\n",
    "\n",
    "# Configuración de etiquetas y título\n",
    "plt.xlabel(\"Valores reales de X1_squared\")\n",
    "plt.ylabel(\"Valores predichos de X2_squared\")\n",
    "plt.title(\"Regresión lineal: X1_squared vs X2_squared\")\n",
    "\n",
    "# Ajustar el layout y eliminar la leyenda\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()\n",
    "\n",
    "# Evaluar el rendimiento del modelo utilizando el error cuadrático medio (MSE)\n",
    "mse = mean_squared_error(y, y_pred)  # Use y instead of y_test\n",
    "print(f\"Error cuadrático medio (MSE): {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preguntas de aprendizaje\n",
    "\n",
    "1. ¿Cómo evaluarón que la regresión fuera adecuada?<br />\n",
    "R = Uno de los indicadores más comunes para evaluar la adecuación de una regresión es el Error Cuadrático Medio (MSE, por sus siglas en inglés), que mide la diferencia promedio entre los valores reales y los valores predichos por el modelo. Un MSE más bajo indica que el modelo está haciendo predicciones más precisas. En este caso, los MSE obtenidos para las relaciones X1 vs Y y X2 vs Y son relativamente bajos (~0.83), lo que sugiere que el modelo ajusta bien los datos en esas relaciones. Sin embargo, el MSE para la relación X1 vs X2 es mucho más alto (35.46), lo que indica que esta regresión tiene un peor ajuste y es menos adecuada para predecir X2 en función de X1. Esto sugiere que las primeras dos relaciones son mejores modelos en comparación con la tercera, al menos en términos de precisión.\n",
    "2. ¿Realizarón algún tipo de transformación no lineal a los datos de entrada? Si fue así, ¿Qué transformación realizaron y por qué?<br />\n",
    "R = Si, se realizaron varias transformaciones no lineales para los puntos. Para el primer gráfico, x1 vs y, como los datos presentan tendencias sinusoidales, pensé en como suavizar primero las ondulaciones y realicé la transformacion con log, luego para atenuar levemente los outliers que harían que la regresión no fuera tan adecuada, multiplique esos datos a los que ya tenian el log aplicado por 0.3. Para el segundo gráfico que fue ligeramente más fácil de linealizar, usé la funcion inversa a e^-x, que es la tendencia que muestran los datos, apliqué la función log. Para el tercer caso, que representaba un círculo, aplique la transformación X^2 e y^2.  \n",
    "3. ¿Considera que los resultados obtenidos son adecuados, o se pueden mejorar?<br />\n",
    "R = Los resultados para las gráficas 1 y 3 siento que podrían mejorar bastante, no se me ocurrieron maás transformaciones que hacer para verdaderamente lograr que los datos quedaran en algo similar a una linea recta.\n",
    "4. ¿Qué puede concluir al final de este proyecto?, escriba su opinión frente a los metodos de regresión lineal y como se aplicó en este proyecto.<br />\n",
    "R = Al final de este proyecto es importante resaltar que los métodos de regresión lineal ayudan a simplificar la visualización de datos que presentan tendencias no lineales y que para este proyecto fueron fundamentales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
